\section{ Lower Bound on the Worst Case Sample Complexity to Solve \QFK}
 \label{app:lowerboundqfk}
%  Before going into the main body of the proof, first, we notice that unlike the best subset selection problem,
%  in this case, there might be multiple solutions. 
%  To prove the lower bound we shall first identify a class of PAC algorithms such that 
%  if there is a PAC algorithm that solves \QFK instance, then there exists
%  a corresponding member in this class, whose ``sampling behaviour'' does not change by permuting the arm indices. An algorithm that belongs to that class we name it as \underbar{P}ermutation \underbar{I}nvariant \underbar{S}ampling \underbar{P}AC \underbar{A}lgorithm (\iispa). Such an algorithm 
%  solve that instance of \QFK using the expected number of samples not more than that of the one in question. Below, we formally define it.
 
% \subsection{Permutation Invariant Sampling}
% Let $J$  be a set of indices such that $|J| = |\A|$. We call a one-to-one association
% between each element of $J$ with an element in $\A$ as indexing, and let 
% $\mathcal{L}(J)$ be the set of all possible indexings with $J$. Therefore, each element of $\mathcal{L}(J)$ gives a different indexing of the arms. For a particular indexing $L$, 
% we denote the bandit instance as $\A(L)$, and the corresponding instance of  \QFK
% as $\QFKL{L}$. 
% Therefore, for a fixed tuple $(\A, n, m, k, \epsilon, \delta)$
% two different indexings $L_1$ and  $L_2$, give rise two different indexed instances--$\QFKL{L_1}$ and $\QFKL{L_2}$.
% We note that the $i$-th arm 
% $a_i \in\A(L_1)$ in $\QFKL{L_1}$ may possibly be different from $a_i \in \A(L_2)$
% in $\QFKL{L_2}$. For convenience, given a \QFK instance, let us define a ``family" of 
% indexed instances as $\F_J \defeq \{\QFKL{L} : L \in \mathcal{L}(J)\}$. We note, given two
% indexings $L_1, L_2 \in \mathcal{L}(J)$, 
% indexed instances $\QFKL{L_1}$,  $\QFKL{L_2} \in \F_J $, if their
% underlying \QFK instances are the identical, and both .
% Also, under any particular indexing $L \in \mathcal{L}(J)$, we denote $\Pr\{\cdot|\QFKL{L}\}$  as $\Pr_L\{\cdot\}$.
 
%  \begin{assumption}
%   For convenience, we shall restrict ourselves to $J = [n]$, where $[n] = \{1, \cdots, n\}$.
%   We shall use $\mathcal{L}$ and $\F$ to denote $\mathcal{L}([n])$, and $\F_{[n]}$
%   respectively.
%  \end{assumption}
 
%  Let, history $H_{T-1} \defeq \{(\mathbf{a}_t, r_t)\}_{t=1}^{T-1}$
%  be a sequence of tuples consisting of index of the arm pulled at $t$, and its instantaneous reward.
%  Also,  given $\A$,
%  let $\mathcalH_{T-1}$ be the set of all possible histories (of length $T-1$) 
%  generated from $\A$. Assume $h(\cdot)$ is a
%  mapping defined as $h: \mathcalH_t \mapsto \D$, where $\D$ is the set of all probability mass
%  functions (p.m.f.) over $\A(L)$. Also, we define a mapping called stopping criterion as
%  $ \textsc{R}_\textsc{S}: \{\mathcalH_T\}_{T=1}^\infty \mapsto \{\textsc{True, False}\}$.
%  We define an algorithm as a map from the set of all instances of \QFK to the set of $k$-sized subsets of $\A$. 
%  Also, it is specified by the tuple $(h, \textsc{R}_\textsc{S})$, such that at each time step $t$, it pulls an 
%  arm $\mathbf{a}_t$ chosen by sampling $h(H_{t-1})$, unless the stopping criterion $\textsc{R}_\textsc{S}(H_{t-1})$
%  becomes \textsc{True}. If $\textsc{R}_\textsc{S}(H_{t-1}) = \textsc{True}$, the algorithm stops and output a 
%  $k$-sized subset from $\A$.
%  At this point, we note an important fact. Letting
%  $\QFKL{L_1}, \QFKL{L_2} \in \F$,
%  suppose $H_{T-1}^1$ and $H_{T-1}^2$ are two histories generated 
%  from $\QFKL{L_1}$ and $\QFKL{L_2}$ respectively. Let, there exists $t \leq T$, such that $H_{t-1}^1 \equiv H_{t-1}^2$,
%  then given an algorithm, $h(H_{t-1}^1) \equiv  h(H_{t-1}^2)$; therefore, 
%  for all $i \in J$, $\Pr_{L_1}(\mathbf{a}_t = a_i | H_{t-1}^1)  = \Pr_{L_2}(\mathbf{a}_t = a_i | H_{t-1}^2)$.

% Now we are ready to formally define the permutation invariant sampling ``behavior'' of PAC algorithms.

%  \begin{definition}[\underbar{P}ermutation \underbar{I}nvariant \underbar{S}ampling \underbar{P}AC \underbar{A}lgorithm (\iispa):]
%   \label{defn:iispa}
%   Given two indexed instances $\QFKL{L_1}$, $\QFKL{L_2}$ $\in \F$, let $\sigma(\cdot)$
%   be the mapping from the index of arm in $\A(L_1)$ to the corresponding index
%   in $\A(L_2)$. In other words, if the arm $a_j \in \A(L_1)$ is indexed as $a_{j'} \in \A(L_2)$,
%   then $\sigma(j) = j'$. Suppose, $H_{t-1}$ is a given history. Also, assume $H_{t-1}'$ is obtained from $H_{t-1}$ by
%   replacing $i$ with $\sigma(i)$, for all $i \in J$; leaving the instantaneous rewards in place.
%   We call a PAC algorithm $ALG$ a \iispa  if 
% %   for given two histories $H_{t-1}$ and $H_{t-1}'$ generated from $A(L_1)$ and $A(L_2)$  respectively, 
%   it satisfies:
%   $\forall i \in J$,
%     $\Pr_{L_1}\{\mathbf{a}_t = a_i |H_{t-1}\} =$ $\Pr_{L_2}\{\mathbf{a}_t = a_{\sigma(i)}|H_{t-1}'\}$. 
% \end{definition}
   
%   Given a history suppose we swap only indices of any two arms, say $i$ and $i'$
%   (keeping their corresponding instantaneous rewards and everything else in place).
%   Intuitively, under the action of \iispa the probability that the $i$-th arm to be pulled in the next round before swapping, will be equal
%   to the probability of the $i'$-th arm after swapping. Next, we are going to show that formally.
  

%  \begin{lemma}
%   \label{lem:iispaevntprob}
%   Let $ALG$ be an  \iispa. We assume a $\QFKL{L} \in \F$, such that there are two arms $a_i, a_{i'} \in A(L)$  (for $i, i' \in J$) which have identical reward distributions. Also, assume for a given  history $H_{t-1}$, that got  generated from $A(L)$, let $H_{t-1}'$ be obtained from it by replacing the occurrences of $a_i$ by $a_{i'}$, and vice-versa (without changing the corresponding instantaneous reward).  Then, under the action of  \textsc{ALG},
%   $\Pr_L\{\mathbf{a}_t = a_i| H_{t-1}\} = \Pr_L\{\mathbf{a}_t = a_{i'}| H_{t-1}'\}$.
%  \end{lemma}
%  \begin{proof}
%   Let us assume, the given statement (in the theorem) is false, 
%   \ie $\Pr_L\{\mathbf{a}_t = a_i| H_{t-1}\} \neq \Pr_L\{\mathbf{a}_t = a_{i'}| H_{t-1}'\}$.
 
  
%   Now, consider $L$ and $L'$ are two different indexings such that the arms $a_i, a_{i'} \in \A(L)$ are respectively mapped to $a_{i'}$ and $a_i$  in $\A(L')$; 
%   however, for any other arm $a_j \in \A(L)$ such that $j \not\in \{i, i'\}$, the index remains the same in $\A(L')$.
%   Now, as $ALG$ is a \iispa, therefore, $\Pr_L\{\mathbf{a}_t = a_i| H_{t-1}\} = \Pr_{L'}\{\mathbf{a}_t = a_{i'}| H_{t-1}'\}$.
%   However, by the definition of an algorithm, given a fixed history, an algorithm generates the
%   same sampling distribution over the arms; hence,
%   $\Pr_{L'}\{\mathbf{a}_t = a_{i'}| H_{t-1}'\} = \Pr_L\{\mathbf{a}_t = a_{i'}| H_{t-1}'\}$,
%   which leads to a contradiction,   thereby proving the theorem.
%  \end{proof}


%  \begin{corollary}
%   \label{cor:iispaevntprob}
% %   \filler{SHOULD WE MOVE IT TO THE MAIN BODY OF THE PROOF? }
%   Let $ALG$ be a \iispa. We are given an $\A(L)$, such that there are two arms $a_i$ and $a_{i'}$ in $\A(L)$
%   whose the reward distributions are identical.
%   Then, under the action of $ALG$ on $\A(L)$ for $t$ time steps, $\Pr_L\{H_{t}\} = \Pr_L\{H_{t}'\}$, where $H_t'$
%   is obtained by replacing the occurrences of $a_i$ by $a_{i'}$, and vice-versa (leaving the corresponding instantaneous rewards in place).
%  \end{corollary}
 
% \begin{theorem}[Existence of Permutation Invariant Sampling PAC Algorithm]
%  \label{defn:idpa2iispa}
% If there is a PAC algorithm that solves \QFK, there exists a \iispa which solves the
% problem, with an expected sample complexity upper bounded by that of the given algorithm.
% \end{theorem}

% \begin{proof}
% We shall prove this theorem by construction.
%  Suppose $\textsc{ALG}^{D}$ is a PAC algorithm that solves \QFK.
% %  Also, assume that $N^D$ be the expected sample
% %  complexity of $\textsc{ALG}^{D}$.
%  Algorithm~\ref{alg:iispa} describes a
%  procedure $\textsc{ALG}^{I}$. We shall show that if $\textsc{ALG}^{D}$ is PAC, then
%   $\textsc{ALG}^{I}$ is \iispa and its expected sample complexity is no more than that of 
%   $\textsc{ALG}^{D}$.
 
% \begin{algorithm}[]
% \DontPrintSemicolon
% \caption{$\textsc{ALG}^{I}$}
% \label{alg:iispa}
%  \KwIn{ $\QFKL{L}, J, \mathcal{L}, \textsc{ALG}^{D}$}
%  Select an element $L' \in \mathcal{L}$ uniformly at random, and determine 
%   $\sigma(\cdot)$, such that $\forall i \in J$, if $a_i \in \A(L)$ is indexed 
%   as  $a_{i'}$ in $L'$, then  $\sigma(i)= i'$.\;
%  Solve $\QFKL{L'}$ using $\textsc{ALG}^{D}$.\;
%  Map the result from $L'$ to $L$ by $\sigma^{-1}(L')$ and return.\;
%  \end{algorithm}
 
%  \textbf{Correctness:} The underlying $\textsc{ALG}^{D}$ being PAC and $\sigma$ being bijective,  $\textsc{ALG}^{I}$ is PAC. 
 
%  \textbf{Permutation Invariant Sampling:} Let us consider $\QFKL{L_1}, \QFKL{L_2} \in \F$.
%   Assume that $a_i \in \A(L_1)$ is indexed as $a_{i'} \in \A(L_2)$.
%   Also, suppose $H_{t-1}$ is the generated history by a run of $\textsc{ALG}^{I}$ on $\A(L)$. 
%  Recalling $L'$ is the indexing chosen by $\textsc{ALG}^{I}$, we notice that the probability of choosing $L'$ from $\mathcal{L}$ is independent
%  of the input indexing. Hence, $\Pr_{L_1}\{L'\} = \Pr_{L_2}\{L'\}$.
 
 
%   Let $\sigma_1 : L_1 \mapsto L'$, and $\sigma_2 : L_2 \mapsto L'$ be two bijective maps.
%  Therefore, letting $\Pr_{L_1}\{L'\} = \Pr_{L_2}\{L'\} = q_{L'}$ we notice
%  $\Pr_{L_1}\{\mathbf{a}_{t} = a_i\} = \sum_{L' \in \mathcal{L}} \Pr_{L'}\{\mathbf{a}_{t} = a_{\sigma_1(i)}\}  \cdot q_{L'} = \sum_{L' \in \mathcal{L}} \Pr_{L'}\{\mathbf{a}_{t} = a_{\sigma_2(i')}\}  \cdot q_{L'} = \Pr_{L_2}\{\mathbf{a}_{t} = a_{i'}\}$. Hence, $\textsc{ALG}^{I}$ is \iispa.
 
%  \textbf{Sample Complexity:}
% %  Considering a fixed index set $J$, 
%  Let $E[SC(\textsc{ALG}) | \QFKL{L}]$ be the expected number of samples incurred by some algorithm $\textsc{ALG}$
%  to solve $\QFKL{L}$. Then, the worst case expected sample complexity of
%  $\textsc{ALG}^{D}$ is given by 
%  $E[SC(\textsc{ALG}^{D})] = \max_{L \in \mathcal{L}} E[SC(\textsc{ALG}^{D})|\QFKL{L}]$.
% %  = N^D$ (say). 
%  Now, letting the probability of picking the $L'$ from $\mathcal{L}$
%  be $q_{L'}$, we get, $E[SC(\textsc{ALG}^{I})] = \sum_{L' \in \mathcal{L}} E[SC(\textsc{ALG}^D) | \QFKL{L'}] \cdot q_{L'} \leq \max_{L' \in \mathcal{L'}} E[SC(\textsc{ALG}^D) | \QFKL{L'}] = E[SC(\textsc{ALG}^{D})]$. 
% %  Now, this is  true for any arbitrary index set $J$.
%  Therefore, the statement follows.
% \end{proof}


% \textbf{NOTE:} From now onward we  shall go by the conventions and notations adopted in the proof of the worst case sample complexity lower bound~\citep[Section 4]{bib:lucb}.

% Now we enter the main proof.
% \subsection{Proof of the Theorem~\ref{thm:lbmainthm}}\label{subsec:lbproof}
% \subsection{The Main Body of the Proof of Lower Bound}
%%%%%%%%%%%%%%% [Lower Bound on Sample Complexity to solve $\textsc{Q-F}_k$] %%%%%%%%%%
\thmlbmainthm*
%%%%%%%%%%%%%%%

The proof technique for Theorem~\ref{thm:lbmainthm} follows a path similar to
that of~\citep[Theorem 8]{bib:lucb}, but
differs in the fact that any $k$ of the $m$ $(\epsilon, m)$-optimal arms
 needs to be returned as opposed to all the $m$. 
%  For convenience, we break the proof into
%  two parts. First, we prove it for the problem instances where either $m \leq 2k -2$ or
%  $m \geq 2k$; then we show that if the lower bound holds for those cases, it must hold
%  for $m= 2k-1$ for a sufficiently small constant.

\subsection{Bandit Instances:}
Assume we are given a set of $n$ arms $\mathcal{A} = \{0, 1, 2, \cdots, n-1\}$.
Let $I_0 \defeq \{0, 1, 2, \cdots, m-k\}$ and
$\I_l \defeq \{I : I\subseteq \{\mathcal{A}\setminus I_0\} \wedge |I| = l\}$.
Also for $I \subseteq \{m-k+1, m-k+2,\cdots,n-1\}$, we define $$\bar{I} \defeq \{m-k+1, m-k+2,\cdots,n-1\} \setminus I.$$

With each $I \in \I_{k-1} \cup \I_m$ we associate an $n$-armed bandit instance $\mathcal{B}^I$,
in which each arm $a$ produces a reward from a Bernoulli distribution with mean
$\mu_a$ defined as:
  \begin{align}
   \mu_a = \begin{cases}
            \frac{1}{2} & \text{ if } a \in I_0\\
        \frac{1}{2} + 2\epsilon & \text{ if } a \in I\\
        \frac{1}{2} - 2\epsilon & \text{ if } a \in \bar{I}.
           \end{cases}
  \end{align}
 Notice that all the instances in $ \I_{k-1} \cup \I_m$ have exactly $m$ $(\epsilon, m)$-optimal
 arms. For $I \in \I_{k-1}$, all the arms in $I_0$ are $(\epsilon, m)$-optimal, but for 
 $I \in \I_m$ they are not. With slight overloading of notation we write 
$\mu(S)$ to denote the multi-set consisting of means of the arms in $S\subseteq \A$.


 The key idea of the proof is that without sufficient  sampling
 of each arm, it is not possible to correctly identify $k$ of the $(\epsilon, m)$-optimal
 arms with high probability.
 
\subsection{Bounding the Error Probability:}
% \textbf{Bounding Error Probability}:
We shall prove the theorem by first making the following assumption, which we
shall demonstrate leads to a contradiction.

\begin{assumption}\label{asmp:contra} 
Assume, that there exists an algorithm $\mathcal{L}$, that solves each problem instance %$(\A, n, m, k, \epsilon, \delta)$
in \QFK defined on bandit instance $\mathcal{B}^I,\; I \in \I_{k-1}$,
 and incurs a sample complexity $\textsc{SC}_I$. Then for all $I \in \I_{k-1}$, 
 $\Ex{\textsc{SC}_I} < \frac{1}{18375}. \frac{1}{\epsilon^2}. \frac{n}{m-k+1}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right)$,
 for $0< \epsilon \leq \frac{1}{\sqrt{32}}$, $0 < \delta \leq \frac{e^{-1}}{4}$, and $n \geq 2m$, where $C = \frac{1}{18375}$.
\end{assumption}

For convenience, we denote by $\Pr_I$ the probability distribution induced by
the bandit instance $\mathcal{B}^I$ and the possible randomisation introduced
by the algorithm $\mathcal{L}$. Also, let $S_{\mathcal{L}}$ be the set of arms returned (as output) by
$\mathcal{L}$, and $T_S$ be the total number of times the arms in  $S \subseteq \mathcal{A}$ get sampled
until $\mathcal{L}$ stops.

Then, as $\mathcal{L}$ solves \QFK, for all $I \in \I_{k-1}$
\begin{equation}
\label{eq:contra}
 \Pr_I\{S_\mathcal{L} \subseteq I_0 \cup I\} \geq 1 - \delta.
\end{equation}

Therefore, for all $I \in \I_{k-1}$
\begin{equation}
 \mathbb{E}_{I}[T_\mathcal{A}] \leq C \frac{n}{m-k+1} \ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right).
\end{equation}


\subsubsection{Changing $\Pr_{I}$ to $\Pr_{I \cup Q}$ where $Q \in \bar{I}$ s.t. $|Q| = m-k+1$: }
Consider an arbitrary but fixed $I \in \I_{k-1}$. Consider a fixed partitioning of $\A$, into $\bfloor{\frac{n}{m-k+1}}$
subsets of size $(m-k+1)$ each.
If Assumption~\eqref{asmp:contra} is correct, then 
for the instance $\mathcal{B}^{I}$,
there are at most $\bfloor{\frac{n}{4(m-k+1})}-1$ partitions $B \subset\bar{I}$, such that $\mathbb{E}_{I}\left[T_B\right] \geq \frac{4C}{\epsilon^2}\ln\left(\frac{1}{4\delta}\right)$.
Now, as $\bfloor{\frac{n-m}{m-k+1}} - \left(\bfloor{\frac{n}{4(m-k+1)}} - 1\right)$ 
% $ > \bfloor{\frac{n}{2(m-k+1)}} - \frac{n}{4(m-k+1)}$
$\geq \bfloor{\frac{n}{4(m-k+1)}} + 1 > 0$;
therefore, there exists at least one subset $Q \in \bar{I}$ such that
$|Q| = m-k+1$, and $\mathbb{E}_{I}\left[T_Q\right] < \frac{4C}{\epsilon^2}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right)$.
Define $T^* = \frac{16C}{\epsilon^2}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right)$. Then
using Markov's inequality we get:
\begin{equation}\label{eq:lbusage}
 \Pr_{I}\left\{T_Q \geq T^*\right\} < \frac{1}{4}.
\end{equation}

Let $\Delta = 2\epsilon T^* + \sqrt{T^*}$ and also let $K_Q$ be the total rewards obtained from $Q$.
\begin{lemma}\label{lem:boundreward}
If $I \in \I_{k-1}$ and $Q \in \bar{I}$ s.t. $|Q| = m-k+1$, then 
 $$\Pr_{I}\left\{T_{Q} \leq T^* \wedge K_{Q} \leq \frac{T_{Q}}{2} - \Delta\right\} \leq \frac{1}{4}\;.$$
\end{lemma}
\begin{proof}
 Let $K_{Q}(t)$ be the total sum obtained from $Q$ at the end of
 the trial $t$. As for $\mathcal{B}^{I_0},\; \forall j\in Q\; \mu_j = 1/2 -2\epsilon$,
 hence selecting and pulling one arm at each trial from $Q$ following any rule (deterministic or probabilistic) is
 equivalent to selection of a single arm from $Q$ for once and subsequently perform
 pulls on it. Hence whatever be the strategy of pulling one arm at each trial from $Q$, the
 expected reward for each pull will be $1/2-2\epsilon$. Let $r_i$ be the i.i.d. reward
 obtained from the $i^\text{th}$ trial. Then $K_{Q}(t) = \sum_{i=1}^t r_i$ and
 $Var\left[r_i\right] = \left(\frac{1}{2} - 2\epsilon\right) \left(\frac{1}{2} + 2\epsilon\right) = \left(\frac{1}{4} - 4\epsilon^2\right) < \frac{1}{4}$.
 As $\forall i: 1 \leq i \leq t$, $r_i$ are i.i.d., we get $Var[K_{Q}(t)] = \sum_{i=1}^tVar(r_i) < \frac{t}{4}$.
 Now we can write the following:
 \begin{eqnarray}
  &&\Pr_{I}\left\{\min\limits_{1\leq t \leq T^*} \left(K_{Q}(t) -t\left(\frac{1}{2}-2\epsilon\right)\right) \leq -\sqrt{T^*}\right\} \nonumber\\
    & \leq & \Pr_{I}\left\{\max\limits_{1\leq t \leq T^*} \left|K_{Q}(t) -t\left(\frac{1}{2}-2\epsilon\right)\right|  \geq  \sqrt{T^*}\right\}\nonumber\\
    & \leq & \frac{Var[K_{Q}(T^*)]}{T^*} < \frac{1}{4},
\end{eqnarray}
 wherein we have used Kolmogorov's inequality.
\end{proof}

\begin{lemma}\label{lem:lb1}
 Let $I \in \I_{k-1}$ and $Q \in \I_{m-k+1}$ such that $Q \subseteq \bar{I}$,
 and let $W$ be some fixed sequence of rewards
 obtained by a single run of algorithm $\mathcal{L}$ on $\mathcal{B}^{I}$ such
 that $T_{Q} \leq T^*$  and $K_{Q} \geq \frac{T_{Q}}{2} - \Delta$, then:
 \begin{equation}
  \Pr_{I \cup Q}\{W\} > \Pr_{I}\{W\}\cdot \exp(-32\epsilon\Delta).
 \end{equation}
\end{lemma}
\begin{proof}
Recall the fact that  all the arms in $Q$ have the same mean. Hence, if chosen
one at each trial (following any strategy), the expected reward at each trial
remains the same. Hence the probability of getting a given reward sequence generated from $Q$
is independent of the sampling strategy.
% by following any sequential strategy will be the same.
%  as the probability of generating that reward sequence by pulling any fixed arm in $Q$.
Again as the arms in
$Q$ have higher mean in $\mathcal{B}^{Q}$, the probability of getting
the sequence (of rewards) decreases monotonically as the 1-rewards for $\mathcal{B}^{I_0}$ become fewer.
So we get
\begin{align}
& \Pr_{I \cup Q}\{W\}  =  \Pr_{I}\{W\} \frac{\left(\frac{1}{2} + 2\epsilon\right)^{K_{Q}} \left(\frac{1}{2} - 2\epsilon\right)^{T_{Q}-K_{Q}}}{\left(\frac{1}{2} - 2\epsilon\right)^{K_{Q}} \left(\frac{1}{2} + 2\epsilon\right)^{T_{Q}-K_{Q}}} \nonumber\\
& \geq \Pr_{I}\{W\} \frac{\left(\frac{1}{2} + 2\epsilon\right)^{\left(\frac{T_{Q}}{2}-\Delta\right)} \left(\frac{1}{2} - 2\epsilon\right)^{\left(\frac{T_{Q}}{2}+\Delta\right)}}{\left(\frac{1}{2} - 2\epsilon\right)^{\left(\frac{T_{Q}}{2}-\Delta\right)} \left(\frac{1}{2} + 2\epsilon\right)^{\left(\frac{T_{Q}}{2}+\Delta\right)}} \nonumber\\
& = \Pr_{I}\{W\}\cdot \left(\frac{\frac{1}{2} - 2\epsilon}{\frac{1}{2} + 2\epsilon}\right)^{2\Delta} \nonumber\\
& >  \Pr_{I}\{W\}\cdot \exp(-32\epsilon\Delta) \left[\text{ for } 0 < \epsilon \leq \frac{1}{\sqrt{32}}\right]\nonumber.
\end{align}
\end{proof}

\begin{lemma}\label{lem:boundallreward}
  If \eqref{eq:lbusage} holds for an $I \in \I_{k-1}$ and $Q \in \I_{m-k+1}$ such that $Q \subseteq \bar{I}$,
  and if $\mathcal{W}$ is the set of all
 possible reward sequences $W$, obtained by algorithm $\mathcal{L}$ on $\mathcal{B}^{I}$, then $\Pr_{I \cup Q}\{\mathcal{W}\} > \left(\Pr_{I}\left\{\mathcal{W}\right\}-\frac{1}{2}\right)\cdot 4\delta.$
%   \begin{equation*}
%     \Pr_{I \cup Q}\{\mathcal{W}\} > \left(\Pr_{I}\left\{\mathcal{W}\right\}-\frac{1}{2}\right)\cdot 4\delta.
%   \end{equation*}
   In particular,
   \begin{equation}\label{eq:err2delta}
    \Pr_{I \cup Q}\{S_\mathcal{L} \subseteq I_0 \cup I\} > \frac{\delta}{\binom{m}{m-k+1}}.
   \end{equation}

\end{lemma}
\begin{proof}
Let for some fixed sequence (of rewards) $W$, $T_{Q}^W$ and $ K_{Q}^W $ respectively
denote the total number of samples received by the arms in $Q$ and the total number of $1$-rewards obtained before the algorithm $\mathcal{L}$ stopped.
Then:
\begin{align*}
 &\Pr_{I \cup Q}\{W\}  = \Pr_{I \cup Q}(W : W \in \mathcal{W}) \nonumber\\
& \geq  \Pr_{I \cup Q}\left\{W : W \in \mathcal{W} \bigwedge T_{Q}^W \leq T^* \bigwedge  K_{Q}^W \geq \frac{T_{Q}^W}{2} - \Delta\right\}\\
& >  \Pr_{I}\left\{W : W \in \mathcal{W} \bigwedge T_{Q}^W \leq T^* \bigwedge  K_{Q}^W \geq \frac{T_{Q}^W}{2} - \Delta\right\}\cdot \exp(-32\epsilon\Delta)\\
& \geq \left(\Pr_{I}\left\{W : W \in \mathcal{W} \bigwedge T_{Q}^W \leq T^*\right\}-\frac{1}{4}\right)\cdot \exp(-32\epsilon\Delta)\\
& \geq  \left(\Pr_{I}\left\{\mathcal{W}\right\}-\frac{1}{2}\right)\cdot \frac{4\delta}{\binom{m}{m-k+1}}\; \text{ for } C = \frac{1}{18375},\; \delta < \frac{e^{-1}}{4} .\\
\end{align*}
 In the above, the $3^\text{rd}$, $4^\text{th}$ and the last step are obtained using Lemma~\ref{lem:lb1}, Lemma~\ref{lem:boundreward} and Equation~\eqref{eq:lbusage}  respectively.
The inequality~\eqref{eq:err2delta} is obtained by using inequality~\eqref{eq:contra},
as $\Pr_{I}\{S_\mathcal{L} \in I_0 \} > 1 - \delta \geq 1 - \frac{e^{-1}}{4} > \frac{3}{4}$.
\end{proof}
% \begin{lemma}\label{lem:probopt}
% Let , $\mathcal{L}$ be a \iispa, and  $I \in \I_{k-1}$ and $Q \in \I_{m-k+1}$ such that $Q \subseteq \bar{I}$. Also, let, a $k$-sized subset $S^* \subseteq I_0 \cup I$ be such that, for any other $S' \subseteq I_0 \cup I$ of the same size,  $ \Pr_{I \cup Q}\{S_\mathcal{L} = S^*: S_\mathcal{L} \subseteq I_0 \cup I\}  \geq  \Pr_{I \cup Q}\{S_\mathcal{L} = S': S_\mathcal{L} \subseteq I_0 \cup I\} $. Then, 
% for any pair $(k,m)$ satisfying $m \leq 2k-2$ or $m \geq 2k$, 
% $$\Pr_{I \cup Q}\{\mu(S_\mathcal{L}) \equiv \mu(S^*)\} > \frac{m-k+1}{\binom{m}{k}} \cdot \frac{\delta}{\binom{m}{m-k+1}}.$$
% \end{lemma}
% \begin{proof}
% As there are total $\binom{m}{k}$ choices for $S_\mathcal{L} \in I_0 \cup I$, $ \Pr_{I \cup Q}\{S_\mathcal{L} = S^*\}  \geq  \frac{1}{\binom{m}{k}}\frac{\delta}{\binom{m}{m-k+1}}$. Now, as $k+1 \leq m \leq 2k-2$ or $m \geq 2k$, for any 
% choice of $S^*$,  there are at least $(m-k)$  different  $k$-sized  subsets  $S' \subseteq I_0\cup I$ other than $S^*$,  such that, $S' \not\equiv S^*$, but $\mu(S) \equiv \mu(S')$; formally,
% $|\{S':  S'  \subset I_0 \cup I \wedge  |S'| = k \wedge S'\not\equiv S^* \wedge \mu(S') \equiv \mu(S^*)\}| \geq m-k$.
% Now, as $\mathcal{L}$ is a \iispa, by Corollary~\ref{cor:iispaevntprob}, each of these $S'$ has the equal probability of being the output. Formally,  $\Pr_{I\cup Q}\{S_\mathcal{L} \equiv S' : S' \subseteq I_0 \cup I \wedge \mu(S') \equiv \mu(S)^*\} = \Pr_{I\cup Q}\{S_\mathcal{L} \equiv S^*\}$. Therefore, summing over all these
% $(m-k+1)$ subsets of $I_0 \cup I$ we prove the lemma.
% \end{proof}
\subsubsection{Summing Over $\I_{k-1}$ and $\I_m$}
Now, we sum up the probability of errors across all the instances in $\I_{k-1}$ and $\I_m$.
If the Assumption~\ref{asmp:contra} is true, using the pigeon-hole principle we show that
there exists some instance for which the mistake probability is greater than $\delta$.

\begin{align*}
 & \sum_{J \in \I_m} \Pr_J\{S_\mathcal{L} \nsubseteq J\} \\
 & \geq \sum_{J \in \I_m} \sum_{\substack{J' \subset J\\ : |J'| = m-k+1}} \Pr_J\{S_\mathcal{L} \subseteq \{J \setminus J'\} \cup I_0\} \\
 & \geq \sum_{J \in \I_m} \sum_{\substack{J' \subset J\\ : |J'| = m-k+1}} \Pr_J\{\exists a \in I_0: S_\mathcal{L} = \{J \setminus J'\} \cup\{a\}\} \\
 & = \sum_{J \in \I_m} \sum_{\substack{J' \subset J\\ : |J'| = m-k+1}} \sum_{I\in\I_{k-1}} \idop[I \cup J'= J] \cdot \Pr_J\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & = \sum_{J \in \I_m} \sum_{\substack{J' \subset \mathcal{A}\setminus I_0\\ : |J'| = m-k+1}} \sum_{I\in\I_{k-1}} \idop[I \cup J'= J] \cdot \Pr_J\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & = \sum_{J \in \I_m}  \sum_{I\in\I_{k-1}} \sum_{\substack{J' \subset \mathcal{A}\setminus I_0\\ : |J'| = m-k+1}}\idop[I \cup J'= J] \cdot \Pr_J\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & = \sum_{I\in\I_{k-1}} \sum_{J \in \I_m} \sum_{\substack{J' \subset \bar{I}\\ : |J'| = m-k+1}}\idop[I \cup J'= J] \cdot \Pr_J\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & = \sum_{I\in\I_{k-1}} \sum_{\substack{J' \subset \bar{I}\\ : |J'| = m-k+1}} \sum_{J \in \I_m} \idop[I \cup J'= J] \cdot \Pr_J\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & = \sum_{I\in\I_{k-1}} \sum_{\substack{J' \subset \bar{I}\\ : |J'| = m-k+1}} \Pr_{I\cup J'}\{S_\mathcal{L} \subseteq I \cup I_0\}
\end{align*}

Recall that $\forall I \in \I_{k-1}$ there exists a set $Q \subset \mathcal{A}\setminus\{I\cup I_0\}: |Q| = (m-k+1)$,
such that $T_Q < T^*$. Therefore,
\begin{align*}
 & \sum_{J \in \I_m} \Pr_J\{S_\mathcal{L} \nsubseteq J\}\\
 & \geq \sum_{I\in\I_{k-1}} \sum_{\substack{J' \subset \bar{I}\\ : |J'| = m-k+1}} \Pr_{I\cup J'}\{S_\mathcal{L} \subseteq I \cup I_0\}\\
 & > \sum_{I\in\I_{k-1}} \sum_{\substack{J' \subset \bar{I}\\ : |J'| = m-k+1}} \frac{\delta}{\binom{m}{m-k+1}}\\
 & \geq \sum_{I\in\I_{k-1}} \binom{n-m}{m-k+1} \cdot \frac{\delta}{\binom{m}{m-k+1}}\\
 & \geq \binom{n-(m-k+1)}{k-1} \cdot \binom{n-m}{m-k+1} \cdot \frac{\delta}{\binom{m}{m-k+1}}\\
 & = \binom{n-(m+k-1)}{m} \delta\\
 & = |\I_m| \delta.
\end{align*}

Hence, we get a  contradiction to Assumption~\ref{asmp:contra}, thereby proving the theorem.
% for $m \leq 2k -2$ and $m \geq 2k$.


% \subsection{Case $m = 2k -1 < \frac{n}{2}$:}

% Let $m_0 = 2k-1$, and let $N_0$ be the worst case sample complexity for $m = m_0$.
% We notice that the identification of $k$ arms from the best
% $m$ arms becomes harder as $m$ decreases.
% Therefore, $N_0$ is not lesser than the minimum number of samples required for $m = m_0 + 1$, and from the previous case we can write
% $ N_0 \geq \frac{1}{18375}\frac{1}{\epsilon^2}. \frac{n}{(m_0+1)-k+1}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right)
%   \geq \frac{1}{36750}\frac{1}{\epsilon^2}. \frac{n}{m_0-k+1}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right).$
% % Therefore, 
% % $$
% % N_0 \geq \frac{1}{18375}\frac{1}{\epsilon^2}. \frac{n}{(m_0+1)-k+1}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right) \geq \frac{1}{36750}\frac{1}{\epsilon^2}. \frac{n}{m_0-k+1}\ln\left(\frac{\binom{m}{m-k+1}}{4\delta}\right).
% % $$
% Hence, Theorem~\ref{thm:lbmainthm} is proved.